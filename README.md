# Toxic-Comment-Classifier

 <h2> Introduction: </h2>
With rise of social media coupled with the Covid-19 pandemic, cyberbullying has reached all time highs. We can combat this by creating models to automatically flag potentially harmful tweets as well as break down the patterns of hatred. 

<h2> Objective: </h2> 
Explore words and patterns associated with each type of cyberbullying
Create a multiclassification model to predict cyberbullying type
Create a binary classification model to flag potentially harmful tweets


<h2> About the Dataset </h2> 
In light of all of this, this dataset contains more than 47000 tweets labelled according to the class of cyberbullying:

Age; <br>
Ethnicity; <br>
Gender; <br> 
Religion; <br> 
Other type of cyberbullying; <br> 
Not cyberbullying The data has been balanced in order to contain ~8000 of each class. <br> 

Trigger Warning These tweets either describe a bullying event or are the offense themselves, therefore explore it to the point where you feel comfortable.
